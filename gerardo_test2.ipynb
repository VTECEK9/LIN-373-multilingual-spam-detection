{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26d12060",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calig\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, Dense, LSTM, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30f31651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>text_hi</th>\n",
       "      <th>text_de</th>\n",
       "      <th>text_fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Dakag बिंदु तक जाओ, पागल. केवल Bag Non महान वि...</td>\n",
       "      <td>Gehen Sie bis jurong Punkt, verrückt.. Verfügb...</td>\n",
       "      <td>Allez jusqu'à Jurong point, fou.. Disponible s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ओके लामर.... if if uue पर.</td>\n",
       "      <td>Ok Lar... joking wif u oni...</td>\n",
       "      <td>J'ai fait une blague sur le wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Fktatatat 21 मई को प्राप्त करने के लिए मुफ्त प...</td>\n",
       "      <td>Freier Eintritt in 2 a wkly comp zum Gewinn FA...</td>\n",
       "      <td>Entrée libre dans 2 a wkly comp pour gagner FA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>Uden इतना जल्दी कहते हैं... तो पहले से ही यूसी...</td>\n",
       "      <td>U dun sagen so früh... U c schon dann sagen...</td>\n",
       "      <td>U dun dit si tôt hor... U c déjà dire alors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>नहीं, मुझे नहीं लगता कि वह हमारे लिए चला जाता ...</td>\n",
       "      <td>Nein, ich glaube nicht, dass er zu unsf geht, ...</td>\n",
       "      <td>Non, je ne pense pas qu'il va à usf, il vit da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>यह 2 सेकंड है जब हमने 2 संपर्क की कोशिश की है....</td>\n",
       "      <td>Dies ist das zweite Mal, dass wir versucht hab...</td>\n",
       "      <td>C'est la 2ème fois que nous avons essayé 2 con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>क्या कलाई घर का पता लगाने के लिए जा रही होगी?</td>\n",
       "      <td>Wird u b gehen, um esplanade fr home?</td>\n",
       "      <td>Est-ce que ü b ira à l'esplanade en maison?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>तो फिर, दूसरे सुझाव क्या हैं?</td>\n",
       "      <td>Schade, * war in Stimmung dafür. Also... irgen...</td>\n",
       "      <td>Dommage, * était d'humeur pour ça. Donc... d'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>आदमी कुछ कुतियािंग किया लेकिन मैं मैं कुछ और ख...</td>\n",
       "      <td>Der Typ hat ein bisschen rumgeschnüffelt, aber...</td>\n",
       "      <td>Le type a fait une saloperie mais j'ai agi com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>उसकी पीठ के नाम पर इसकी सच्चाई</td>\n",
       "      <td>Rofl. Es ist seinem Namen treu</td>\n",
       "      <td>Rofl. C'est vrai à son nom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5157 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     labels                                               text  \\\n",
       "0       ham  Go until jurong point, crazy.. Available only ...   \n",
       "1       ham                      Ok lar... Joking wif u oni...   \n",
       "2      spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3       ham  U dun say so early hor... U c already then say...   \n",
       "4       ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "...     ...                                                ...   \n",
       "5567   spam  This is the 2nd time we have tried 2 contact u...   \n",
       "5568    ham               Will ü b going to esplanade fr home?   \n",
       "5569    ham  Pity, * was in mood for that. So...any other s...   \n",
       "5570    ham  The guy did some bitching but I acted like i'd...   \n",
       "5571    ham                         Rofl. Its true to its name   \n",
       "\n",
       "                                                text_hi  \\\n",
       "0     Dakag बिंदु तक जाओ, पागल. केवल Bag Non महान वि...   \n",
       "1                            ओके लामर.... if if uue पर.   \n",
       "2     Fktatatat 21 मई को प्राप्त करने के लिए मुफ्त प...   \n",
       "3     Uden इतना जल्दी कहते हैं... तो पहले से ही यूसी...   \n",
       "4     नहीं, मुझे नहीं लगता कि वह हमारे लिए चला जाता ...   \n",
       "...                                                 ...   \n",
       "5567  यह 2 सेकंड है जब हमने 2 संपर्क की कोशिश की है....   \n",
       "5568      क्या कलाई घर का पता लगाने के लिए जा रही होगी?   \n",
       "5569                      तो फिर, दूसरे सुझाव क्या हैं?   \n",
       "5570  आदमी कुछ कुतियािंग किया लेकिन मैं मैं कुछ और ख...   \n",
       "5571                     उसकी पीठ के नाम पर इसकी सच्चाई   \n",
       "\n",
       "                                                text_de  \\\n",
       "0     Gehen Sie bis jurong Punkt, verrückt.. Verfügb...   \n",
       "1                         Ok Lar... joking wif u oni...   \n",
       "2     Freier Eintritt in 2 a wkly comp zum Gewinn FA...   \n",
       "3        U dun sagen so früh... U c schon dann sagen...   \n",
       "4     Nein, ich glaube nicht, dass er zu unsf geht, ...   \n",
       "...                                                 ...   \n",
       "5567  Dies ist das zweite Mal, dass wir versucht hab...   \n",
       "5568              Wird u b gehen, um esplanade fr home?   \n",
       "5569  Schade, * war in Stimmung dafür. Also... irgen...   \n",
       "5570  Der Typ hat ein bisschen rumgeschnüffelt, aber...   \n",
       "5571                     Rofl. Es ist seinem Namen treu   \n",
       "\n",
       "                                                text_fr  \n",
       "0     Allez jusqu'à Jurong point, fou.. Disponible s...  \n",
       "1              J'ai fait une blague sur le wif u oni...  \n",
       "2     Entrée libre dans 2 a wkly comp pour gagner FA...  \n",
       "3        U dun dit si tôt hor... U c déjà dire alors...  \n",
       "4     Non, je ne pense pas qu'il va à usf, il vit da...  \n",
       "...                                                 ...  \n",
       "5567  C'est la 2ème fois que nous avons essayé 2 con...  \n",
       "5568        Est-ce que ü b ira à l'esplanade en maison?  \n",
       "5569  Dommage, * était d'humeur pour ça. Donc... d'a...  \n",
       "5570  Le type a fait une saloperie mais j'ai agi com...  \n",
       "5571                         Rofl. C'est vrai à son nom  \n",
       "\n",
       "[5157 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('data-en-hi-de-fr.csv')\n",
    "data_df.dropna(inplace=True)\n",
    "data_df.drop_duplicates(inplace=True)\n",
    "data_df.rename(columns={\n",
    "    \"Category\": \"labels\",\n",
    "    \"Message\": \"text\"\n",
    "}, inplace=True)\n",
    "\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1cea53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>text_hi</th>\n",
       "      <th>text_de</th>\n",
       "      <th>text_fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Dakag बिंदु तक जाओ, पागल. केवल Bag Non महान वि...</td>\n",
       "      <td>Gehen Sie bis jurong Punkt, verrückt.. Verfügb...</td>\n",
       "      <td>Allez jusqu'à Jurong point, fou.. Disponible s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ओके लामर.... if if uue पर.</td>\n",
       "      <td>Ok Lar... joking wif u oni...</td>\n",
       "      <td>J'ai fait une blague sur le wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Fktatatat 21 मई को प्राप्त करने के लिए मुफ्त प...</td>\n",
       "      <td>Freier Eintritt in 2 a wkly comp zum Gewinn FA...</td>\n",
       "      <td>Entrée libre dans 2 a wkly comp pour gagner FA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>Uden इतना जल्दी कहते हैं... तो पहले से ही यूसी...</td>\n",
       "      <td>U dun sagen so früh... U c schon dann sagen...</td>\n",
       "      <td>U dun dit si tôt hor... U c déjà dire alors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>नहीं, मुझे नहीं लगता कि वह हमारे लिए चला जाता ...</td>\n",
       "      <td>Nein, ich glaube nicht, dass er zu unsf geht, ...</td>\n",
       "      <td>Non, je ne pense pas qu'il va à usf, il vit da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>यह 2 सेकंड है जब हमने 2 संपर्क की कोशिश की है....</td>\n",
       "      <td>Dies ist das zweite Mal, dass wir versucht hab...</td>\n",
       "      <td>C'est la 2ème fois que nous avons essayé 2 con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>क्या कलाई घर का पता लगाने के लिए जा रही होगी?</td>\n",
       "      <td>Wird u b gehen, um esplanade fr home?</td>\n",
       "      <td>Est-ce que ü b ira à l'esplanade en maison?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>तो फिर, दूसरे सुझाव क्या हैं?</td>\n",
       "      <td>Schade, * war in Stimmung dafür. Also... irgen...</td>\n",
       "      <td>Dommage, * était d'humeur pour ça. Donc... d'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>आदमी कुछ कुतियािंग किया लेकिन मैं मैं कुछ और ख...</td>\n",
       "      <td>Der Typ hat ein bisschen rumgeschnüffelt, aber...</td>\n",
       "      <td>Le type a fait une saloperie mais j'ai agi com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>उसकी पीठ के नाम पर इसकी सच्चाई</td>\n",
       "      <td>Rofl. Es ist seinem Namen treu</td>\n",
       "      <td>Rofl. C'est vrai à son nom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5157 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                               text  \\\n",
       "0          0  Go until jurong point, crazy.. Available only ...   \n",
       "1          0                      Ok lar... Joking wif u oni...   \n",
       "2          1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3          0  U dun say so early hor... U c already then say...   \n",
       "4          0  Nah I don't think he goes to usf, he lives aro...   \n",
       "...      ...                                                ...   \n",
       "5567       1  This is the 2nd time we have tried 2 contact u...   \n",
       "5568       0               Will ü b going to esplanade fr home?   \n",
       "5569       0  Pity, * was in mood for that. So...any other s...   \n",
       "5570       0  The guy did some bitching but I acted like i'd...   \n",
       "5571       0                         Rofl. Its true to its name   \n",
       "\n",
       "                                                text_hi  \\\n",
       "0     Dakag बिंदु तक जाओ, पागल. केवल Bag Non महान वि...   \n",
       "1                            ओके लामर.... if if uue पर.   \n",
       "2     Fktatatat 21 मई को प्राप्त करने के लिए मुफ्त प...   \n",
       "3     Uden इतना जल्दी कहते हैं... तो पहले से ही यूसी...   \n",
       "4     नहीं, मुझे नहीं लगता कि वह हमारे लिए चला जाता ...   \n",
       "...                                                 ...   \n",
       "5567  यह 2 सेकंड है जब हमने 2 संपर्क की कोशिश की है....   \n",
       "5568      क्या कलाई घर का पता लगाने के लिए जा रही होगी?   \n",
       "5569                      तो फिर, दूसरे सुझाव क्या हैं?   \n",
       "5570  आदमी कुछ कुतियािंग किया लेकिन मैं मैं कुछ और ख...   \n",
       "5571                     उसकी पीठ के नाम पर इसकी सच्चाई   \n",
       "\n",
       "                                                text_de  \\\n",
       "0     Gehen Sie bis jurong Punkt, verrückt.. Verfügb...   \n",
       "1                         Ok Lar... joking wif u oni...   \n",
       "2     Freier Eintritt in 2 a wkly comp zum Gewinn FA...   \n",
       "3        U dun sagen so früh... U c schon dann sagen...   \n",
       "4     Nein, ich glaube nicht, dass er zu unsf geht, ...   \n",
       "...                                                 ...   \n",
       "5567  Dies ist das zweite Mal, dass wir versucht hab...   \n",
       "5568              Wird u b gehen, um esplanade fr home?   \n",
       "5569  Schade, * war in Stimmung dafür. Also... irgen...   \n",
       "5570  Der Typ hat ein bisschen rumgeschnüffelt, aber...   \n",
       "5571                     Rofl. Es ist seinem Namen treu   \n",
       "\n",
       "                                                text_fr  \n",
       "0     Allez jusqu'à Jurong point, fou.. Disponible s...  \n",
       "1              J'ai fait une blague sur le wif u oni...  \n",
       "2     Entrée libre dans 2 a wkly comp pour gagner FA...  \n",
       "3        U dun dit si tôt hor... U c déjà dire alors...  \n",
       "4     Non, je ne pense pas qu'il va à usf, il vit da...  \n",
       "...                                                 ...  \n",
       "5567  C'est la 2ème fois que nous avons essayé 2 con...  \n",
       "5568        Est-ce que ü b ira à l'esplanade en maison?  \n",
       "5569  Dommage, * était d'humeur pour ça. Donc... d'a...  \n",
       "5570  Le type a fait une saloperie mais j'ai agi com...  \n",
       "5571                         Rofl. C'est vrai à son nom  \n",
       "\n",
       "[5157 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(data_df.labels)\n",
    "data_df[\"labels\"] = le.transform(data_df.labels)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6014af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset indices after preprocessing to ensure alignment\n",
    "data_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(data_df.text, data_df.labels, stratify=data_df.labels, test_size=0.3, random_state=123)\n",
    "train_x_fr, test_x_fr, train_y_fr, test_y_fr = train_test_split(data_df.text_fr, data_df.labels, stratify=data_df.labels, test_size=0.3, random_state=123)\n",
    "train_x_de, test_x_de, train_y_de, test_y_de = train_test_split(data_df.text_de, data_df.labels, stratify=data_df.labels, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bab3bb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spacy models for French and German\n",
    "nlp_fr = spacy.load('fr_core_news_sm')\n",
    "nlp_de = spacy.load('de_core_news_sm')\n",
    "\n",
    "def preprocess_text(text, nlp):\n",
    "    doc = nlp(text.lower().strip())\n",
    "    return \" \".join([token.lemma_ for token in doc if not token.is_punct and not token.is_stop and not token.like_num])\n",
    "\n",
    "data_df['processed_text_fr'] = data_df['text_fr'].apply(preprocess_text, nlp=nlp_fr)\n",
    "data_df['processed_text_de'] = data_df['text_de'].apply(preprocess_text, nlp=nlp_de)\n",
    "\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "089f676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer setup\n",
    "tokenizer_fr = Tokenizer(num_words=5000)\n",
    "tokenizer_de = Tokenizer(num_words=5000)\n",
    "\n",
    "# Fit on the processed texts\n",
    "tokenizer_fr.fit_on_texts(data_df['processed_text_fr'])\n",
    "tokenizer_de.fit_on_texts(data_df['processed_text_de'])\n",
    "\n",
    "# Convert texts to sequences\n",
    "sequences_fr = tokenizer_fr.texts_to_sequences(data_df['processed_text_fr'])\n",
    "sequences_de = tokenizer_de.texts_to_sequences(data_df['processed_text_de'])\n",
    "\n",
    "# Padding sequences to the same length\n",
    "max_sequence_len = 150\n",
    "X_seq_fr = pad_sequences(sequences_fr, maxlen=max_sequence_len)\n",
    "X_seq_de = pad_sequences(sequences_de, maxlen=max_sequence_len)\n",
    "\n",
    "# Splitting the data using the already defined splits\n",
    "X_train_seq_fr = X_seq_fr[train_x_fr.index]\n",
    "X_test_seq_fr = X_seq_fr[test_x_fr.index]\n",
    "X_train_seq_de = X_seq_de[train_x_de.index]\n",
    "X_test_seq_de = X_seq_de[test_x_de.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d82572b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1356\n",
      "           1       0.87      0.89      0.88       192\n",
      "\n",
      "    accuracy                           0.97      1548\n",
      "   macro avg       0.93      0.94      0.93      1548\n",
      "weighted avg       0.97      0.97      0.97      1548\n",
      "\n",
      "German Naive Bayes Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1356\n",
      "           1       0.89      0.90      0.89       192\n",
      "\n",
      "    accuracy                           0.97      1548\n",
      "   macro avg       0.94      0.94      0.94      1548\n",
      "weighted avg       0.97      0.97      0.97      1548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vectorizer for French and German\n",
    "vectorizer_fr = CountVectorizer(max_features=5000)\n",
    "vectorizer_de = CountVectorizer(max_features=5000)\n",
    "\n",
    "# Fit and transform the data\n",
    "X_vect_fr = vectorizer_fr.fit_transform(data_df['processed_text_fr'])\n",
    "X_vect_de = vectorizer_de.fit_transform(data_df['processed_text_de'])\n",
    "\n",
    "# Use indices to get train and test sets\n",
    "X_train_vect_fr = X_vect_fr[train_x_fr.index]\n",
    "X_test_vect_fr = X_vect_fr[test_x_fr.index]\n",
    "X_train_vect_de = X_vect_de[train_x_de.index]\n",
    "X_test_vect_de = X_vect_de[test_x_de.index]\n",
    "\n",
    "# Initialize and train Naive Bayes for French\n",
    "nb_model_fr = MultinomialNB()\n",
    "nb_model_fr.fit(X_train_vect_fr, train_y_fr)\n",
    "y_pred_fr = nb_model_fr.predict(X_test_vect_fr)\n",
    "print(\"French Naive Bayes Classification Report:\")\n",
    "print(classification_report(test_y_fr, y_pred_fr))\n",
    "\n",
    "# Initialize and train Naive Bayes for German\n",
    "nb_model_de = MultinomialNB()\n",
    "nb_model_de.fit(X_train_vect_de, train_y_de)\n",
    "y_pred_de = nb_model_de.predict(X_test_vect_de)\n",
    "print(\"German Naive Bayes Classification Report:\")\n",
    "print(classification_report(test_y_de, y_pred_de))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f192e367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating RNN for French:\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calig\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.8738 - loss: 0.4073 - val_accuracy: 0.9474 - val_loss: 0.1934\n",
      "Epoch 2/5\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9651 - loss: 0.1336 - val_accuracy: 0.9751 - val_loss: 0.0965\n",
      "Epoch 3/5\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9835 - loss: 0.0636 - val_accuracy: 0.9806 - val_loss: 0.0713\n",
      "Epoch 4/5\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9917 - loss: 0.0412 - val_accuracy: 0.9820 - val_loss: 0.0605\n",
      "Epoch 5/5\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9954 - loss: 0.0196 - val_accuracy: 0.9778 - val_loss: 0.0737\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9725 - loss: 0.0776\n",
      "Test Accuracy: 97.42%\n",
      "Training and evaluating RNN for German:\n",
      "Epoch 1/5\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8214 - loss: 0.4371 - val_accuracy: 0.9224 - val_loss: 0.2019\n",
      "Epoch 2/5\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9597 - loss: 0.1315 - val_accuracy: 0.9654 - val_loss: 0.1154\n",
      "Epoch 3/5\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9872 - loss: 0.0579 - val_accuracy: 0.9723 - val_loss: 0.0811\n",
      "Epoch 4/5\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9887 - loss: 0.0454 - val_accuracy: 0.9723 - val_loss: 0.0718\n",
      "Epoch 5/5\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9940 - loss: 0.0327 - val_accuracy: 0.9765 - val_loss: 0.0690\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9842 - loss: 0.0710\n",
      "Test Accuracy: 98.26%\n"
     ]
    }
   ],
   "source": [
    "def build_and_train_rnn(X_train, y_train, X_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=5000, output_dim=64, input_length=150))\n",
    "    model.add(Dropout(0.2))  # Dropout for input layer\n",
    "    model.add(SimpleRNN(64, dropout=0.2))  # Applying dropout to RNN\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
    "    \n",
    "# Train and evaluate for French\n",
    "print(\"Training and evaluating RNN for French:\")\n",
    "build_and_train_rnn(X_train_seq_fr, train_y_fr, X_test_seq_fr, test_y_fr)\n",
    "\n",
    "# Train and evaluate for German\n",
    "print(\"Training and evaluating RNN for German:\")\n",
    "build_and_train_rnn(X_train_seq_de, train_y_de, X_test_seq_de, test_y_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c846976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 94ms/step - accuracy: 0.8572 - loss: 0.4227 - val_accuracy: 0.9446 - val_loss: 0.2065\n",
      "Epoch 2/5\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.9518 - loss: 0.1721 - val_accuracy: 0.9737 - val_loss: 0.1204\n",
      "Epoch 3/5\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.9794 - loss: 0.0806 - val_accuracy: 0.9848 - val_loss: 0.0674\n",
      "Epoch 4/5\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 93ms/step - accuracy: 0.9928 - loss: 0.0370 - val_accuracy: 0.9834 - val_loss: 0.0507\n",
      "Epoch 5/5\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.9932 - loss: 0.0246 - val_accuracy: 0.9875 - val_loss: 0.0441\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9824 - loss: 0.0679\n",
      "Test Accuracy: 98.00%\n",
      "Epoch 1/5\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - accuracy: 0.8458 - loss: 0.4369 - val_accuracy: 0.9377 - val_loss: 0.2057\n",
      "Epoch 2/5\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.9431 - loss: 0.1938 - val_accuracy: 0.9668 - val_loss: 0.1328\n",
      "Epoch 3/5\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.9788 - loss: 0.0884 - val_accuracy: 0.9875 - val_loss: 0.0658\n",
      "Epoch 4/5\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.9863 - loss: 0.0543 - val_accuracy: 0.9861 - val_loss: 0.0449\n",
      "Epoch 5/5\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.9886 - loss: 0.0386 - val_accuracy: 0.9917 - val_loss: 0.0370\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9820 - loss: 0.0637\n",
      "Test Accuracy: 98.19%\n"
     ]
    }
   ],
   "source": [
    "def build_and_train_lstm(X_train, y_train, X_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=5000, output_dim=64, input_length=150))\n",
    "    model.add(Dropout(0.2))  # Dropout on input layer\n",
    "    model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))  # Dropout within LSTM layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "# Train and evaluate for French\n",
    "build_and_train_lstm(X_train_seq_fr, train_y_fr, X_test_seq_fr, test_y_fr)\n",
    "\n",
    "# Train and evaluate for German\n",
    "build_and_train_lstm(X_train_seq_de, train_y_de, X_test_seq_de, test_y_de)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
